{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Author:  Leo Pauly (cnlp@leeds.ac.uk) & Nick Wilson (n.wilson@lubs.leeds.ac.uk)\n",
      "Description: Autmatic database update: Conversion\n"
     ]
    }
   ],
   "source": [
    "print('Author:  Leo Pauly (cnlp@leeds.ac.uk) & Nick Wilson (n.wilson@lubs.leeds.ac.uk)')\n",
    "print('Description: Autmatic database update: Conversion')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Usage intructions & Other info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Change/Add User (user variable options: 'leo','nick')\n",
    "2. Change file_formate variable (options: '.sav','.csv')\n",
    "3. Prefefably install python using anacodna (all in one installation): https://www.anaconda.com/products/individual#windows\n",
    "4. Run this if 'pyarrow' module is missing':  !pip install pyarrow \n",
    "5. Converted database are stored in the directory : UKLTD_Database "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python version: 3.8.5 (default, Sep  3 2020, 21:29:08) [MSC v.1916 64 bit (AMD64)]\n",
      "No: of logical CPU cores available: 8\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pyreadstat\n",
    "from zipfile import ZipFile\n",
    "import pyunpack\n",
    "import multiprocessing\n",
    "import dask.dataframe as dd\n",
    "import time\n",
    "import dask\n",
    "from dask.diagnostics import ProgressBar\n",
    "from dask.distributed import Client\n",
    "dask.config.set(scheduler='threads')\n",
    "import gc\n",
    "\n",
    "print('Python version:',sys.version)\n",
    "num_processes = multiprocessing.cpu_count()\n",
    "print('No: of logical CPU cores available:',num_processes)\n",
    "\n",
    "AC01_header_dtypes={'AC01': 'O', 'REGNUM': 'O','ACCDAT_start': 'O','ACCDAT': 'O', 'number_of_weeks':'float64', 'months':'float64', 'currency': 'O', 'consolidated': 'O', 'acctype': 'float64', 'Turnover': 'float64', 'Export': 'float64', 'Cost_of_Sales': 'float64', 'Gross_Profit': 'float64', 'Wages_Salaries': 'float64', 'Directors_Emoluments': 'float64', 'Operating_Profits': 'float64', 'Depreciation': 'float64', 'Audit_Fees': 'float64', 'Interest_Payments': 'float64', 'Pre_Tax_Profit': 'float64', 'taxation1': 'float64', 'Profit_After_Tax': 'float64', 'Dividends_Payable': 'float64', 'Retained_Profits': 'float64', 'Tangible_Assets': 'float64', 'Intangible_Assets': 'float64', 'Total_Fixed_Assets': 'float64', 'Total_Current_Assets': 'float64', 'Trade_Debtors': 'float64', 'Stock': 'float64', 'Cash': 'float64', 'Other_Current_Assets': 'float64', 'Increase_In_Cash': 'float64', 'Mis_Current_Assets': 'float64', 'Total_Assets': 'float64', 'Total_Current_Liabilities': 'float64', 'Trade_Creditors': 'float64', 'Bank_Overdraft': 'float64', 'Other_Short_Term_Fin': 'float64', 'Mis_Current_Liabilities': 'float64', 'Other_Long_Term_Fin': 'float64', 'Total_Long_Term_Liabilities': 'float64', 'Bank_Overdraft_LTL': 'float64', 'Total_Liabilities': 'float64', 'Net_Assets': 'float64', 'Working_Capital': 'float64', 'Paid_up_equity': 'float64', 'PL_Account_Weserve': 'float64', 'Sundry_Weserves': 'float64', 'Revaluation_Weserve': 'float64', 'Shareholder_Funds': 'float64', 'NetWorth': 'float64', 'NetCashflowfromOperations': 'float64', 'NetCashflowbeforeFinancing': 'float64', 'NetCashflowfromFinancing': 'float64', 'Contingent_Liability': 'float64', 'Capital_Employed': 'float64', 'No_Employees': 'float64', 'status': 'float64', 'UPLOAD': 'O'}\n",
    "AC01_header_names=['AC01', 'REGNUM', 'ACCDAT_start', 'ACCDAT', 'number_of_weeks', 'months', 'currency', 'consolidated', 'acctype', 'Turnover', 'Export', 'Cost_of_Sales', 'Gross_Profit', 'Wages_Salaries', 'Directors_Emoluments', 'Operating_Profits', 'Depreciation', 'Audit_Fees', 'Interest_Payments', 'Pre_Tax_Profit', 'taxation1', 'Profit_After_Tax', 'Dividends_Payable', 'Retained_Profits', 'Tangible_Assets', 'Intangible_Assets', 'Total_Fixed_Assets', 'Total_Current_Assets', 'Trade_Debtors', 'Stock', 'Cash', 'Other_Current_Assets', 'Increase_In_Cash', 'Mis_Current_Assets', 'Total_Assets', 'Total_Current_Liabilities', 'Trade_Creditors', 'Bank_Overdraft', 'Other_Short_Term_Fin', 'Mis_Current_Liabilities', 'Other_Long_Term_Fin', 'Total_Long_Term_Liabilities', 'Bank_Overdraft_LTL', 'Total_Liabilities', 'Net_Assets', 'Working_Capital', 'Paid_up_equity', 'PL_Account_Weserve', 'Sundry_Weserves', 'Revaluation_Weserve', 'Shareholder_Funds', 'NetWorth', 'NetCashflowfromOperations', 'NetCashflowbeforeFinancing', 'NetCashflowfromFinancing', 'Contingent_Liability', 'Capital_Employed', 'No_Employees', 'status', 'UPLOAD']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Selectting file format\n",
    "file_format='sav' #(options: csv,sav)\n",
    "\n",
    "## Selectting user\n",
    "user='leo' #(user variable options: 'leo','nick')\n",
    "\n",
    "## Adding filepaths\n",
    "if(user=='leo'):\n",
    "    base_dir='C:/Users/cnlp/Research Fellowship/'\n",
    "elif(user=='nick'):\n",
    "    base_dir='/Volumes/Pegasus32 R6/CreditSafe 2019 Zipped/'\n",
    "\n",
    "os.makedirs(base_dir+'UKLTD_Database', exist_ok=True)\n",
    "dir_list_file=base_dir+'/UKLTD_Scripts/dir_list.txt'\n",
    "database_file_folder=base_dir+'UKLTD_Database/AC01/'\n",
    "\n",
    "if (file_format=='csv'): \n",
    "    database_file=base_dir+'UKLTD_Database/AC01/AC01.csv'\n",
    "elif (file_format=='sav'): \n",
    "    database_file=base_dir+'UKLTD_Database/AC01/AC01.sav'\n",
    "else:\n",
    "    print('File format not supported')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loading database "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Database found. Reading database! \n",
      "\n",
      "Time taken to read database C:/Users/cnlp/Research Fellowship/UKLTD_Database/AC01/: 0.046875 s\n",
      "No: of partitions in the database: 4\n"
     ]
    }
   ],
   "source": [
    "## If databse is in .csv format \n",
    "if (os.path.exists(database_file_folder)):\n",
    "    print('Database found.','Reading database! \\n') \n",
    "    start = time.process_time()\n",
    "    with ProgressBar():\n",
    "        df_database = dd.read_parquet(database_file_folder) \n",
    "    print('Time taken to read database {}:'.format(database_file_folder),time.process_time() - start,'s')\n",
    "    database_missing=False\n",
    "else:\n",
    "    print('Database missing.  \\n')\n",
    "    exit()\n",
    "    \n",
    "print('No: of partitions in the database:',df_database.npartitions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Converting and writing into disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[########################################] | 100% Completed |  0.1s\n",
      "Time taken to write: 0.171875 s\n"
     ]
    }
   ],
   "source": [
    "## Writing converted databse to file\n",
    "if (file_format=='csv'):\n",
    "    start = time.process_time()\n",
    "    with ProgressBar():\n",
    "        df_database.to_csv(database_file,single_file=True)\n",
    "    print('Time taken to write:',time.process_time() - start,'s')\n",
    "elif (file_format=='sav'):\n",
    "    start = time.process_time()\n",
    "    with ProgressBar():\n",
    "        pyreadstat.write_sav(df_database.compute(),database_file)\n",
    "    print('Time taken to write:',time.process_time() - start,'s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
